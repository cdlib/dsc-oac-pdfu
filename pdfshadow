#!/usr/bin/env python
""" pdfshadow
    creates shadow directory structure for XTF
"""
from __future__ import unicode_literals
import sys
import os, inspect
import argparse
import logging
import boto
import urlparse

def main(argv=None):

    parser = argparse.ArgumentParser( description='create shadow directory for XTF')
    parser.add_argument('bucket', nargs=1, help="s3://bucket[/optional/path]")
    parser.add_argument('shadowdir', nargs=1, help="Output Directory" )
    parser.add_argument('--loglevel', default='ERROR', required=False)

    if argv is None:
        argv = parser.parse_args()

    # set debugging level
    numeric_level = getattr(logging, argv.loglevel.upper(), None)
    if not isinstance(numeric_level, int):
        raise ValueError('Invalid log level: %s' % argv.loglevel)
    logging.basicConfig(level=numeric_level, )

    # call the function that does the work
    shadow(argv.bucket[0], argv.shadowdir[0])

def shadow(bucketurl, dir):
    parts = urlparse.urlsplit(bucketurl)  # SplitResult(scheme='s3', netloc='test.pdf', path='/dkd', query='', fragment='')
    s3 = boto.connect_s3()
    bucket = s3.get_bucket(parts.netloc)
    for key in bucket.list():
        # look for pdfs that match the user supplied path
        if key.name.endswith(u'.pdf') and not parts.path or key.name.startswith(parts.path[1:]):
            shadowdir, shadowfile = os.path.split(key.name)
            shadowdir = os.path.join(dir, shadowdir)
            if not os.path.isdir(shadowdir):
                os.makedirs(shadowdir)
            shadowfile = open(os.path.join(shadowdir, shadowfile), "w")
            shadowfile.write(str(key.size))
            shadowfile.close()

# main() idiom for importing into REPL for debugging 
if __name__ == "__main__":
    sys.exit(main())
